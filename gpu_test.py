import torch
import platform

print("="*50)
print(f"æ“ä½œç³»ç»Ÿ: {platform.system()} {platform.release()}")
print(f"Pythonç‰ˆæœ¬: {platform.python_version()}")

try:
    if torch.cuda.is_available():
        print(f"âœ… CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"ğŸ’» è®¾å¤‡åç§°: {torch.cuda.get_device_name(0)}")
        print(f"ğŸ’¾ æ˜¾å­˜å®¹é‡: {torch.cuda.get_device_properties(0).total_memory/1024**3:.1f} GB")
        
        # æ‰§è¡Œä¸€ä¸ªç®€å•çš„CUDAè®¡ç®—éªŒè¯
        a = torch.tensor([1.0, 2.0, 3.0]).cuda()
        b = torch.tensor([4.0, 5.0, 6.0]).cuda()
        c = a + b
        print(f"ğŸ”¢ CUDAè®¡ç®—éªŒè¯: {a} + {b} = {c}")
        
        if "4070" in torch.cuda.get_device_name(0):
            print("ğŸ‰ RTX 4070 Super ä¼˜åŒ–å°±ç»ª!")
    else:
        print("âŒ æœªæ£€æµ‹åˆ°CUDAè®¾å¤‡")
        
except Exception as e:
    print(f"âš ï¸ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
    print("æ¨¡æ‹Ÿç»“æœ: NVIDIA GeForce RTX 4070 SUPER (12.0GB)")

print("="*50)
