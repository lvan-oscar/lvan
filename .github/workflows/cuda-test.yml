name: Robust CUDA Test
on: [push]

jobs:
  cuda-test:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    # 使用具有GPU支持的运行器（如果可用）
    # runs-on: [self-hosted, gpu]  # 如果有自建GPU运行器
    
    services:
      # 启动一个支持CUDA的Docker服务
      cuda-container:
        image: nvidia/cuda:12.1.1-base
        options: --gpus all
        
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        
    - name: Install NVIDIA drivers and CUDA
      run: |
        # 添加NVIDIA仓库
        curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
        distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
        curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
        
        # 安装驱动和工具包
        sudo apt-get update
        sudo apt-get install -y nvidia-driver-535 nvidia-container-toolkit nvidia-cuda-toolkit
        sudo systemctl restart docker
        
        # 验证安装
        nvidia-smi
        nvcc --version
        
    - name: Install PyTorch with compatible dependencies
      run: |
        # 安装兼容的NumPy
        pip install numpy==1.26.0
        
        # 安装PyTorch套件
        pip install torch==2.1.0+cu121 torchvision==0.16.0+cu121 torchaudio==2.1.0+cu121 \
          --index-url https://download.pytorch.org/whl/cu121 \
          --no-deps
          
        # 安装其他必要依赖
        pip install pillow requests jinja2
        
    - name: Run CUDA tests
      run: |
        echo "===== PyTorch Info ====="
        python -c "import torch; print(f'PyTorch version: {torch.__version__}')"
        
        echo "===== CUDA Availability ====="
        python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
        
        echo "===== Device Info ====="
        python -c "import torch; print(f'Device count: {torch.cuda.device_count()}')"
        python -c "import torch; print(f'Current device: {torch.cuda.current_device()}')"
        python -c "import torch; print(f'Device name: {torch.cuda.get_device_name(0)}')"
        
        echo "===== Custom Test ====="
        python gpu_test.py
